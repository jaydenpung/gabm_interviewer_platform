{% load static %}

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>GABM</title>

    <meta name="description" content="" />

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="{% static 'gabm/sneat/assets/img/favicon/favicon.ico' %}" />

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Public+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet" />

    <!-- Core CSS -->
    <link rel="stylesheet" href="{% static 'gabm/sneat/assets/vendor/css/rtl/core.css' %}" class="template-customizer-core-css" />
    <link rel="stylesheet" href="{% static 'gabm/sneat/assets/vendor/css/rtl/theme-default.css' %}" class="template-customizer-theme-css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" />

    <style>
      body {
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        background: linear-gradient(45deg, #6e45e2, #88d3ce);
      }

      button {
        padding: 10px 20px;
        border: none;
        border-radius: 5px;
        background-color: #fff;
        color: #333;
        font-size: 16px;
        cursor: pointer;
        margin: 10px;
        transition: background-color 0.3s, transform 0.2s;
      }

      button:hover {
        background-color: #f8f9fa;
        transform: scale(1.05);
      }

      button:active {
        transform: scale(0.95);
      }

      @keyframes flashGreen {
        0%, 100% {
          box-shadow: 0 0 15px rgba(255, 255, 255, 0.6), 
                      0 0 25px rgba(255, 255, 255, 0.6), 
                      0 0 35px rgba(255, 255, 255, 0.6);
        }
        50% {
          box-shadow: 0 0 15px rgba(0, 255, 0, 0.8), 
                      0 0 25px rgba(0, 255, 0, 0.8), 
                      0 0 35px rgba(0, 255, 0, 0.8);
        }
      }

      .flash-animation {
        animation: flashGreen 6s ease-in-out;
      }

      #visualizer {
        visibility: hidden;
        position: relative;
        width: 180px;
        height: 180px;
        background-color: #fff;
        border-radius: 50%;
        border: 2px solid #fff;
        position: absolute;
        left: 50%;
        top: 38%;
        transform: translate(-50%, -50%) scale(1);
        transition: transform 0.1s ease;
        box-shadow: 0 0 15px rgba(255, 255, 255, 0.6), 0 0 25px rgba(255, 255, 255, 0.6), 0 0 35px rgba(255, 255, 255, 0.6);
        display: flex;
        justify-content: center;
        align-items: center;
      }

      #micIcon, #speakerIcon, #thinkingIcon {
        position: absolute;
        top: 38%;
        left: 50%;
        transform: translate(-50%, -50%);
      }

      #speakerIcon{ 
        width:2.5em;
      }

      #micIcon{ 
        font-size:1.8em; 
      }

      #visualizer>i {
        position: absolute;
        font-size: 2em;
        color: rgb(110, 129, 255);
      }

      #controls {
        position: fixed;
        bottom: 70px;
        left: 50%;
        transform: translateX(-50%);
      }

      #endButton {
        display: none;
        opacity: 0; /* Start with the button invisible */
        transition: opacity 2s; /* Gradual fade effect over 2 seconds */
        margin-bottom: 0.7em;
      }

      #interviewerTranscriptContainer {
        display:none; 
        width:400px; 
        margin: 0 auto;  
        padding:1.8em; 
        color:white; 
        border-radius: 1.5em; 
        margin-bottom: 1em;
        max-height: 108px; 
        overflow-y: scroll; 
        text-align: left;
      }
    
      #refresh {
        color: rgba(255, 255, 255, 1);
        font-weight: 900;
      }

      #refresh:hover {
        color: rgba(255, 255, 255, 1);
        font-weight: 600;
      }

      /* This is CSS specifically for audio play animation when the agent is
        thinking about its next lines */
      #thinkingIcon {
        display: none;
        justify-content: center;
        align-items: center;
        height: 100vh;
        opacity: 0; /* Make it invisible initially */
        transition: opacity 2s; /* Adjust time as needed */
      }

      .circle {
        width: 24px;
        height: 24px;
        margin: 0 10px;
        background-color: white; /* You can change the color */
        border-radius: 50%;
        animation: wave 1.5s ease-in-out infinite;
        box-shadow: 0 0 15px rgba(255, 255, 255, 0.6), 0 0 25px rgba(255, 255, 255, 0.6), 0 0 35px rgba(255, 255, 255, 0.6);
      }

      .circle:nth-child(2) {
        animation-delay: 0.1s;
      }

      .circle:nth-child(3) {
        animation-delay: 0.2s;
      }

      @keyframes wave {
        0%, 100% {
          transform: translateY(0);
        }
        50% {
          transform: translateY(-20px);
        }
      }

      /* Now for the instructions */
      #interaction_wrapper {
        position: absolute;
        z-index:100;  
      }

      /* For the instruction */
      #instructions {
        background-color: white; 
        padding:3em; 
        border-radius: 2em; 
        box-shadow: 0 0 15px rgba(255, 255, 255, 0.22), 0 0 25px rgba(255, 255, 255, 0.22), 0 0 35px rgba(255, 255, 255, 0.22);
      }

      #instructions h1 {
        font-size:1.5em
      }

      #instructions p {
        font-size:1.1em; 
        margin-top:1.8em
      }

      #instructions ul {
        font-size:1.1em
      }

      /* Now for the progress bar */
      #progressBarWrapper {
        visibility: hidden;
        margin-bottom: 2em;
        border:none;
      }

      #progressBar {
        position: relative;
        padding: 10px;
        border-bottom:solid;
        background-image: url("{% static 'gabm/img/walk2.png' %}");
        background-size: auto 110%;
        background-position: center center; 
        width:400px;
        height:72px;
        border-radius: 20px;
        border:none;
      }

      #avatar {
        position: absolute;
        left: 1%;
        width: 32px;
        top: 50%;
        transform: translateY(-50%);
        transition: left 5s ease; 
      }

      /* Styles for screens with a height less than 600px */
      @media screen and (max-height: 599px) {
          #micIcon, #speakerIcon, #thinkingIcon, #visualizer {
              top: 20%;
          }
      }

      /* Styles for screens with a height between 600px and 799px */
      @media screen and (min-height: 600px) and (max-height: 799px) {
          #micIcon, #speakerIcon, #thinkingIcon, #visualizer {
              top: 30%;
          }
      }

      /* Styles for screens with a height of 800px or more */
      @media screen and (min-height: 800px) {
          #micIcon, #speakerIcon, #thinkingIcon, #visualizer {
              top: 38%;
          }
      }

      #savedMessage {
        display: none; 
        opacity: 0; 
        transition: opacity 2s;
        color: rgba(0, 255, 0, 0.8);
        font-weight: 900;
        font-size: 1.1em;
      }
    </style>
  </head>

  <body>
    <div id="interaction_wrapper" class="row" style="">
      <div class="col-lg-3 col-md-3 col-sm-2 col-0"></div>
      <div class="col-lg-6 col-md-6 col-sm-8 col-12" style="padding:2em">
        <div id="instructions">
          <h1>
            <em style="">Are you ready?</em>
          </h1>
          <p>
            Please note:
          </p>
          <ul>
            <li>Ensure your speaker and microphone are turned on. If your browser prompts you to enable them, please do so.</li>
            <li>You can start speaking when you see this icon: <strong><i class="fa fa-microphone" style=""></i></strong></li>
            <li>A white circle at the center of the screen will enlarge when it detects your voice. It will gradually fade if you stop talking.</li>
            <li>Your progress will be indicated by a circular ring that will gradually grow around Isabella's sprite avatar. If it becomes a full circle, you are done!</li>
          </ul><br>
          <div style="text-align:center; z-index:100 !important">
            <button id="startButton" class="btn rounded-pill btn-info" style="z-index:100 !important"><strong>Click here to start the interview</strong></button>
          </div>
        </div>
      </div>

      <div id="controls" style="width:100%; text-align:center; display: none">

        <div id="interviewerTranscriptContainer" style="">
          <p id="interviewerTranscript" style=""></p>
        </div>

        {% if user_avatar.front_gif %}
        <div class="row" id="progressBarWrapper">
          <div class="col-lg-3 col-md-3 col-sm-2 col-0"></div>
          <div class="col-lg-6 col-md-6 col-sm-8 col-12" >
            <div id="progressBar" style="margin: 0 auto;">
              <img id="avatar" src="{{ user_avatar.right_gif.url }}" alt="Front Avatar" style="">
            </div>
          </div>
        </div>
        {% endif %}
        
        <div id="interviewControls" style="display: none; text-align:center; ">    
          
          <button id="buttonShowTranscript" class="btn rounded-pill btn-info" style="border-width:2px"><strong id="buttonShowTranscriptInner">Show Isabella's subtitles</strong></button>

          <button id="buttonPause" class="btn btn-icon rounded-pill btn-outline-facebook" 
            data-bs-toggle="modal" data-bs-target="#modals-pause" 
            style="border-width:5px; color: rgba(255, 255, 255, 0.85);"><strong><i class="fa-solid fa-pause"></i></strong></button>

          <button id="buttonInfo" class="btn btn-icon rounded-pill btn-outline-facebook" 
            data-bs-toggle="modal" data-bs-target="#modals-info" 
            style="border-width:5px"><strong><i class="fa-solid fa-info"></i></strong></button>

        </div>
        <a href="{% url 'home' %}" id="endButton" type="button" class="btn rounded-pill btn-info"><strong>Click here to return to the main page</strong></a>
 
        <div id="refreshContainer" style="width: 400px;  margin: 0 auto; visibility: hidden; border-radius: 20px; background-color: red; margin-top:1.2em; padding:0.2em; box-shadow: 0 0 15px rgba(255, 255, 255, 0.22), 0 0 25px rgba(255, 255, 255, 0.22), 0 0 35px rgba(255, 255, 255, 0.22);">
            <a id="refresh" data-bs-toggle="modal" data-bs-target="#modals-refresh" >
              Help! Isabella froze for 60+ seconds.
            </a>
        </div>
      </div>
    </div>

    <div id="container" style="">
      <div id="visualizer">
        <img id="progressImage" src="{% static 'gabm/img/progress_arcs_thick/0.png' %}" style="width:17em; visibility: hidden;" />
      </div>
      <i id="micIcon" class="fa fa-microphone" style="display: none"></i>
      <img id="speakerIcon" src="{% static 'gabm/img/Isabella_Rodriguez.png' %}" style="display: none" />
      <span id="thinkingIcon" style="display: none">
        <div class="circle"></div>
        <div class="circle"></div>
        <div class="circle"></div>
      </span>

      <br>
      <br>
      <span id="savedMessage">[ Progress saved ]</span>
    </div>


    <!-- Modal template -->
    <div class="modal modal-transparent fade" id="modals-pause" tabindex="-1">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
            <a style="box-shadow: none;"
              href="javascript:void(0);"
              class="btn-close text-white"
              data-bs-dismiss="modal"
              aria-label="Close"></a>
            <div class="input-group input-group-lg mb-3" style="background-color: white; border-radius:1.5em; box-shadow: 0 0 15px rgba(255, 255, 255, 0.3), 0 0 25px rgba(255, 255, 255, 0.3), 0 0 35px rgba(255, 255, 255, 0.3); padding:3em">
              This interview is designed to be completed in one sitting, and we do not recommend pausing it. However, we understand that unexpected circumstances may arise, prompting you to pause and restart the interview.
              <br>
              <br>
              If you pause, we will ask you to resume your interview from your last saved checkpoint, which is indicated by a "green light" flashing around the circle.
              <div style="width:100%; text-align: center; display: block; margin-top:2em">
                <a href="{% url 'home' %}" id="test" class="btn rounded-pill btn-instagram"><strong><i class="fa-solid fa-pause"></i> &nbsp;&nbsp;|&nbsp;&nbsp; Pause the interview</strong></a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal template -->
    <div class="modal modal-transparent fade" id="modals-info" tabindex="-1">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
            <a style="box-shadow: none;"
              href="javascript:void(0);"
              class="btn-close text-white"
              data-bs-dismiss="modal"
              aria-label="Close"></a>
            <div class="input-group input-group-lg mb-3" style="background-color: white; border-radius:1.5em; box-shadow: 0 0 15px rgba(255, 255, 255, 0.3), 0 0 25px rgba(255, 255, 255, 0.3), 0 0 35px rgba(255, 255, 255, 0.3); padding:3em">
              If you have any questions about the study, or if anything breaks, please email the admin at pungkahheng@gmail.com
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal template -->
    <div class="modal modal-transparent fade" id="modals-refresh" tabindex="-1">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="modal-body">
            <a style="box-shadow: none;"
              href="javascript:void(0);"
              class="btn-close text-white"
              data-bs-dismiss="modal"
              aria-label="Close"></a>
            <div class="input-group input-group-lg mb-3" style="background-color: white; border-radius:1.5em; box-shadow: 0 0 15px rgba(255, 255, 255, 0.3), 0 0 25px rgba(255, 255, 255, 0.3), 0 0 35px rgba(255, 255, 255, 0.3); padding:2.4em">
              If Isabella has not responded for over a minute, you may need to refresh the page. This will let you resume from the last saved check point. 
              <div style="width:100%; text-align: center; display: block; margin-top:2em;">
                <a href="{% url 'interview' script_v %}" id="test" class="btn rounded-pill btn-info"><strong><i class="fa-solid fa-arrows-rotate"></i> &nbsp;&nbsp;|&nbsp;&nbsp; Refresh the page</strong></a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <script>
      // #####################################################################
      // [SECTION 1: SETTING VARIABLES]

      // Handles for HTML elements:
      let visualizerElement = document.getElementById('visualizer');
      let progressImage = document.getElementById('progressImage');
      let micIcon = document.getElementById('micIcon');
      let speakerIcon = document.getElementById('speakerIcon');

      // Web Audio API objects. 
      let audioContext;
      let agentAnalyser, userAnalyser; 
      let userProcessor;
      let mediaRecorder;

      // Settings and parameters: 
      const speechThreshold = {{ request.user.audio_calibration_float }};
      const maxSilenceDuration = 6;
      const fade_exponent = 3;
      const recentRMSsSizes = 10;
      const RPTStartThreshold = 3;
      // const RPTStartThreshold = 1;
      const RPTEndThreshold = 5; 

      // State variables: 
      let silenceStarted;
      let isUserTurn = false;
      let userHasSpoken = false;
      let currRMS;
      let recentRMSs = []
      let currentAudioElement = null;
      let audioChunks = [];
      let isLoading = false;
      let startUtteranceTime;
      let mediaSilenceResetTimer = 0;
      let realMediaOnStop = false;
      // let loadingTimer = null;


      // #####################################################################
      // [SECTION 2: HELPER FUNCTIONS]

      /**
       * Retrieves a cookie value by its name.
       * @param {string} name The name of the cookie.
       * @return {?string} The value of the cookie, or null if not found.
       */
      function getCookie(name) {
        let cookieValue = null;
        if (document.cookie && document.cookie !== '') {
          const cookies = document.cookie.split(';');
          for (let i = 0; i < cookies.length; i++) {
            const cookie = cookies[i].trim();
            // Check if the cookie string begins with the name we want.
            if (cookie.substring(0, name.length + 1) === (name + '=')) {
              const cookiePart = cookie.substring(name.length + 1);
              cookieValue = decodeURIComponent(cookiePart);
              break;
            }
          }
        }
        return cookieValue;
      }
      const csrftoken = getCookie('csrftoken');


      /**
       * Calculates the file size in bytes from a Base64 string.
       * @param {string} base64String The Base64 encoded string.
       * @return {number} The calculated file size in bytes.
       */
      function calculateBase64FileSize(base64String) {
        // Remove header from data URL, if present
        let base64WithoutHeader = base64String.split(',')[1] || base64String;

        // Adjust for padding
        let padding = 0;
        if (base64WithoutHeader.endsWith('==')) {
          padding = 2;
        } else if (base64WithoutHeader.endsWith('=')) {
          padding = 1;
        }

        // Calculate the total number of bits in the base64 string (6 bits per
        // character)
        let totalBits = base64WithoutHeader.length * 6;
        // Subtract the padding bits (8 bits per '=' character)
        let adjustedBits = totalBits - padding * 8;
        // Convert bits to bytes
        let fileSizeInBytes = adjustedBits / 8;

        return fileSizeInBytes;
      }


      // #####################################################################
      // [SECTION 3: DECORATION]

      /**
       * Updates the icons' visuals based on the current stage.
       */
      function updateIcons() {
        if (isLoading) {
          // <Part 1. Icon when the agent is thinking of the next line>
          visualizer.style.backgroundColor = 'transparent';
          visualizer.style.borderColor = 'transparent';
          visualizer.style.boxShadow = "none";
          progressImage.style.display = 'none';

          micIcon.style.display = 'none';
          speakerIcon.style.display = 'none';
          thinkingIcon.style.display = 'flex';

          // Fade in for the thinking animation
          var loadingContainer = document.querySelector('#thinkingIcon');
          loadingContainer.style.display = 'none';
 
          function fadeInLoading() {
            loadingContainer.style.display = 'flex'; // Set display to flex
            setTimeout(() => {
              loadingContainer.style.opacity = 1; // Start the fade in
            }, 15); // Timeout allows CSS to recognize the display change
          }
          fadeInLoading();

        } else if (isUserTurn) {
          // Icon for when the user is speaking
          visualizer.style.backgroundColor = 'white';
          visualizer.style.borderColor = 'white';
          visualizer.style.boxShadow = '0 0 15px rgba(255, 255, 255, 0.6), ' +
                                       '0 0 25px rgba(255, 255, 255, 0.6), ' +
                                       '0 0 35px rgba(255, 255, 255, 0.6)';
          progressImage.style.display = 'flex';
          micIcon.style.display = 'block';
          speakerIcon.style.display = 'none';
          thinkingIcon.style.display = 'none';

          document.getElementById('refreshContainer').style.visibility = 'hidden';

        } else {
          // Icon for when the agent is speaking
          visualizer.style.backgroundColor = 'white';
          visualizer.style.borderColor = 'white';
          visualizer.style.boxShadow = '0 0 15px rgba(255, 255, 255, 0.6), ' +
                                       '0 0 25px rgba(255, 255, 255, 0.6), ' +
                                       '0 0 35px rgba(255, 255, 255, 0.6)';
          progressImage.style.display = 'flex';
          micIcon.style.display = 'none';
          speakerIcon.style.display = 'block';
          thinkingIcon.style.display = 'none';

          document.getElementById('refreshContainer').style.visibility = 'hidden';
        }
      }


      // #####################################################################
      // [SECTION 3: CORE FUNCTIONS]

      /**
       * Returns the number of recent RMS values that exceeded the speech 
       * threshold.
       * @param {number} RMS The current RMS value.
       * @return {number} The count of recent RMS values exceeding the 
       * threshold.
       */
      function getRecentPassedThreshold(RMS) {
        // If RMS is higher than the speechThreshold, we add 1 to the 
        // recentRMSs, which is a list of floats (RMSs) with the length of
        // recentRMSsSizes. If it is lower or equal, we add 0. 
        let passedThreshold = 0;
        if (RMS > speechThreshold) {
          // console.log(RMS + " :: "  + speechThreshold);
          passedThreshold += 1;
        }
        recentRMSs.push(passedThreshold);

        // Remove the oldest entry if there are more than 20 items
        if (recentRMSs.length > recentRMSsSizes) {
          recentRMSs.shift(); 
        }

        // Sum up the values using reduce
        const recentPassedThreshold = recentRMSs.reduce(
          (accumulator, currentValue) => accumulator + currentValue, 0
        ); 
        return recentPassedThreshold
      }

      /**
       * Calculates the Root Mean Square (RMS) of the audio input.
       * @param {AudioProcessingEvent} audioProcessingEvent The audio 
       * processing event.
       */
      function calculateRMS(audioProcessingEvent) {
        const inputBuffer = audioProcessingEvent.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);
        let sumSquares = 0.0;
        for (let i = 0; i < inputData.length; i++) {
          sumSquares += inputData[i] * inputData[i];
        }
        currRMS = Math.sqrt(sumSquares / inputData.length);
      }

      /**
       * Handles the beginning and end of speech based on RMS thresholds.
       * @param {number} recentPassedThreshold The recent passed threshold 
       * value.
       */
      function handleSpeechBeginAndEnd(recentPassedThreshold) {
        // console.log(mediaSilenceResetTimer);
        if (mediaRecorder.state === "inactive") {
          mediaRecorder.start();
          mediaSilenceResetTimer = 0;
        }

        if (mediaRecorder.state === "recording" && !userHasSpoken){
          mediaSilenceResetTimer += 1
          if (mediaSilenceResetTimer % 150 === 0) {
            realMediaOnStop = false;
            mediaRecorder.stop();
            mediaRecorder.start();
            mediaSilenceResetTimer = 0;
          }
        }

        if (recentPassedThreshold > RPTStartThreshold && !userHasSpoken) {
          userHasSpoken = true;
          startUtteranceTime = new Date()
          // console.log("STARTING MEDIA RECORDER")
          // mediaRecorder.start();
        }
        if (userHasSpoken) {
          if (currRMS <= speechThreshold) {
            silenceStarted = silenceStarted || new Date();
          } else if (recentPassedThreshold < RPTEndThreshold) {
            silenceStarted = false;
          }
          // 600000 stands for 10 minutes... So we want to end if it's been 10 minutes... 
          if ((silenceStarted && (new Date() - silenceStarted > maxSilenceDuration * 1000)) ||
            (new Date() - startUtteranceTime > 600000)) {
            isLoading = true;
            isUserTurn = false;
            userHasSpoken = false;
            silenceStarted = false;
            realMediaOnStop = true;
            mediaRecorder.stop();
          }
        }
      }

      /**
       * Calculates the duration of silence.
       * @return {number} The duration of silence in seconds.
       */
      function calculateSecSilence() {
        if (!silenceStarted) {
          return 0;
        }
        const currTime = new Date();
        return (currTime - silenceStarted) / 1000;
      }

      /**
       * Applies a fade away effect based on the duration of silence.
       * @param {number} secSilence The duration of silence in seconds.
       */
      function applyFadeAwayEffect(secSilence) {
        let silenceRatio = secSilence / maxSilenceDuration;
        let fadeFactor = Math.pow(silenceRatio, fade_exponent);
        let opacity = Math.max(1 - fadeFactor, 0);
        opacity = opacity < 0.01 ? 0 : opacity;
        visualizerElement.style.opacity = opacity;
        micIcon.style.opacity = opacity;
      }

      function checkLoadingStatus() {
          let loadingTimer = null;
          // loadingTimer = null;

          const interval = setInterval(() => {
              if (isLoading) {
                  if (loadingTimer === null) {
                      loadingTimer = setTimeout(() => {
                        document.getElementById('refreshContainer').style.visibility = 'visible';
                        clearInterval(interval); // Stop the interval once the condition is met
                      }, 52000); // 52 seconds
                  }
              } else {
                  if (loadingTimer !== null) {
                      clearTimeout(loadingTimer); // Clear the timeout if isLoading becomes false
                      loadingTimer = null;
                  }
              }
          }, 5000); // Check every second
        }


      /**
       * Animates the agent and interviewee's voice, and records the 
       * interviewee's voice. 
       */
      function animateAndRecord() {
        window.requestAnimationFrame(animateAndRecord);
        let analyser = isUserTurn ? userAnalyser : agentAnalyser;
        
        // Frequency data handling
        let dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray);

        // Calculation of average frequency and RMS
        let sum = dataArray.reduce((a, b) => a + b, 0);
        let average = sum / dataArray.length;
        let scale = 1 + (average / 64);

        // Apply the scale transformation to the visualizer element. But this
        // is only if the agent is speaking, or if we have determined that the
        // user started speaking. 
        if (!isUserTurn || userHasSpoken) {
          let transformValue = `translate(-50%, -50%) scale(${scale})`;
          visualizerElement.style.transform = transformValue;
        }

        // <User's turn handler>
        // If this is the user's turn, we do a couple of things here: 
        // 1) Make the visualizer circle gradually fade away as the user stops
        //    speaking
        // 2) Start recording if we detect that the user started to talk, and 
        //    end the recording if we determine that they are done. 
        if (isUserTurn) {
          userProcessor.onaudioprocess = calculateRMS;

          const recentPassedThreshold = getRecentPassedThreshold(currRMS);
          handleSpeechBeginAndEnd(recentPassedThreshold);

          // Fade away effect
          let secSilence = calculateSecSilence();
          applyFadeAwayEffect(secSilence);
        }

        // Update any icons or graphics
        updateIcons();

        checkLoadingStatus();
      }


      function showSavedMessage() {
          var message = document.getElementById('savedMessage');
          message.style.display = 'block';
          message.style.opacity = '1';

          // Start fading out after 5 seconds
          setTimeout(function() {
              message.style.opacity = '0';
          }, 6000);

          // Set display none after transition is complete (2 seconds for fade out + 5 seconds delay)
          setTimeout(function() {
              message.style.display = 'none';
          }, 8000);
      }


      

      // #####################################################################
      /**
       * Plays the audio sound from a given audio element.
       * @param {HTMLAudioElement} newAudioElement The audio element to play.
       */
      function playAudio(newAudioElement, curr_data) {
        // Create the audio source and connect to the analyser
        let agentSource = audioContext.createMediaElementSource(newAudioElement);
        agentSource.connect(agentAnalyser);
        agentAnalyser.connect(audioContext.destination);

        // Play logic based on the state of current audio
        if (currentAudioElement && !currentAudioElement.ended) {
          currentAudioElement.onended = () => {
            // Play the new audio element
            newAudioElement.play();
            // Update the interviewer transcript container with the current data
            document.getElementById('interviewerTranscriptContainer').innerHTML = "<strong>Isabella:</strong> " + curr_data["interviewer_transcript"];
          };
        } else {
          newAudioElement.play();
          document.getElementById('interviewerTranscriptContainer').innerHTML = "<strong>Isabella:</strong> " + curr_data["interviewer_transcript"];
        }
        currentAudioElement = newAudioElement;
      }

      /**
       * Displays the end button.
       */
      function showEndButton() {
        document.getElementById('interviewControls').style.display = 'none';
        document.getElementById('refreshContainer').style.display = 'none';

        var button = document.getElementById("endButton");
        button.style.display = "inline-flex";
        setTimeout(() => button.style.opacity = 1, 10);
      }

      /**
       * Handles the completion of the interview.
       */
      function handleInterviewCompletion() {
        if (!currentAudioElement || currentAudioElement.ended) {
          audioContext.close();
          showEndButton();
        } else {
          currentAudioElement.onended = () => {
            audioContext.close();
            showEndButton();
          };
        }
      }

      /**
       * Handles the user's media stream.
       * @param {MediaStream} stream The media stream to process.
       */
      function handleUserMedia(stream) {
        const userSource = audioContext.createMediaStreamSource(stream);
        userProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        userSource.connect(userAnalyser);
        userSource.connect(userProcessor);
        userProcessor.connect(audioContext.destination);

        let mimeType = 'audio/webm';  // Default mimeType
        if (MediaRecorder.isTypeSupported('audio/mp4')) {
          mimeType = 'audio/mp4';  // Use MP4 if supported
        }

        // Initializing MediaRecorder
        mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });

        // Push audio data into chunks array when data is available
        mediaRecorder.ondataavailable = event => {
          audioChunks.push(event.data);
        };

        // Behavior of mediaRecorder upon stopping
        mediaRecorder.onstop = () => {
          if (realMediaOnStop) {
            const audioBlob = new Blob(audioChunks, { 'type' : mimeType });
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);

            // Convert Blob to base64 and include in newData
            const reader = new FileReader();
            reader.readAsDataURL(audioBlob); 
            reader.onloadend = function() {
              const base64data = reader.result;
              var newData = {
                started: false, 
                user_utt: base64data, 
                script_v: "{{script_v}}", 
                mime_type: mimeType
              };

              // Log file size in bytes
              const fileSizeInBytes = calculateBase64FileSize(base64data);
              // console.log("File size in bytes:", fileSizeInBytes);

              // Recursive call with new or modified data
              take_one_step(newData); 
            }
          } else {
            audioChunks = [];
          }
        };
      }

      function animateAvatarToPosition(percentage) {
        if (percentage < 0 || percentage > 100) {
            // console.error("Percentage should be between 0 and 100");
            return;
        }

        var avatar = document.getElementById("avatar");
        avatar.style.left = percentage + "%";
      }


      /**
       * This is the main recursive loop for the interviewer agent.
       * @param {Object} data The data to be processed in each step.
       */
      function take_one_step(data) {
        // POST call to send data from frontend to backend server
        fetch('{% url "handler_take_one_step" %}', {
          method: 'POST',
          body: JSON.stringify(data),
          headers:{
            'Content-Type': 'application/json',
            'X-CSRFToken': csrftoken
          }
        })
        .then(response => response.json())
        .then(data => {
          // Update progress image
          // console.log(data)
          if (data["progress_circle_rad"] !== undefined) {
            const progressImage = document.getElementById('progressImage');
            progressImage.src = data.progress_circle_url;
            // console.log("fin_percent: " + data["fin_percent"]);
            animateAvatarToPosition(data["fin_percent"]);
          }

          if (data["interview_completed"] == true) {
            // Completing the interview
            handleInterviewCompletion();
          } else {
            // Handling ongoing interview process
            // Playing the interviewer agent's voice audio
            isLoading = false;
            let audio_path = data["audio_url"];
            let audioElement = new Audio(audio_path);
            audioElement.crossOrigin = "anonymous";
            if (audio_path) { 
              playAudio(audioElement, data);
            }
            animateAndRecord();

            // console.log("IMPORTANT DEBUGGIN")
            // console.log(data["completed"]);

            if (data["module_completed"]) {
                // Add the animation class
              // Call this function when you want to show the message
              showSavedMessage();

                visualizerElement.classList.add('flash-animation');
                
                // Optional: Remove the class after the animation ends
                visualizerElement.addEventListener('animationend', function() {
                  visualizerElement.classList.remove('flash-animation');
                });
            }


            // document.getElementById('interviewerTranscriptContainer').innerHTML = "<strong>Isabella:</strong> " + data["interviewer_transcript"];

            // Record the user response
            if (!data["skip_user_utt"]) {
              audioElement.onended = function() {
                isUserTurn = true; 
                userHasSpoken = false;　

                audioChunks = [];
                if (navigator.mediaDevices.getUserMedia) {
                  navigator.mediaDevices.getUserMedia ({audio: true})
                  .then(handleUserMedia)
                  .catch(err => console.log('gUM error: ' + err));
                } else {
                  console.log('getUserMedia not supported on your browser!');
                }
              }
            } else {
              var newData = {
                started: false, 
                user_utt: null, 
                script_v: "{{script_v}}", 
                mime_type: null
              };
              take_one_step(newData); 
            }
          };
        })
        .catch(error => console.error('Error:', error));
      }


      // #####################################################################
      // [SECTION 5: DEFINING THE START BUTTON]
      // Defining the start button's behavior
      document.getElementById('startButton')
        .addEventListener('click', function() {
        // Hide the start button and instructions once clicked
        document.getElementById('instructions').style.display = 'none';
        document.getElementById('controls').style.display = 'block';
        
        this.style.display = "none";

        // Hide the start button and instructions once clicked
        document.getElementById('interviewControls').style.display = 'block';
        document.getElementById('refreshContainer').style.visibility = 'hidden';
        document.getElementById('visualizer').style.visibility = 'visible';
        document.getElementById('progressBarWrapper').style.visibility = 'visible';

        // Setup of Web Audio API variables
        if (!audioContext && navigator.mediaDevices.getUserMedia) {
          const AudioCtx = window.AudioContext || window.webkitAudioContext;
          audioContext = new AudioCtx();
          agentAnalyser = audioContext.createAnalyser();
          agentAnalyser.fftSize=2048
          userAnalyser = audioContext.createAnalyser();
          userAnalyser.fftSize=2048
        }

        // Data for the first interaction with the backend
        let data = {
          started: true, 
          user_utt: null, 
          script_v: "{{script_v}}", 
          mime_type: null
        };
        // Start the recursive calls
        take_one_step(data); 
      });


      document.getElementById('buttonShowTranscript')
        .addEventListener('click', function() {
          var transcriptContainer = document.getElementById('interviewerTranscriptContainer');
          if (transcriptContainer.style.display === 'block') {
              transcriptContainer.style.display = 'none';
              document.getElementById('buttonShowTranscriptInner').innerHTML = "Show Isabella's subtitles";
          } else {
              transcriptContainer.style.display = 'block';
              document.getElementById('buttonShowTranscriptInner').innerHTML = "Hide Isabella's subtitles";
          }
      });
    </script>

    <script src="{% static 'gabm/sneat/assets/vendor/libs/jquery/jquery.js' %}"></script>
    <script src="{% static 'gabm/sneat/assets/vendor/js/bootstrap.js' %}"></script>
    <script src="{% static 'gabm/sneat/assets/js/ui-modals.js' %}"></script>

  </body>
</html>






